{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "chubby-polls",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting prueba.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile prueba.py\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd # data processing\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "import seaborn as sns\n",
    "\n",
    "class data_class():\n",
    "\n",
    "    \n",
    "    def __init__(self, root=\"../../\"):\n",
    "        self.root = \"../../\"\n",
    "           \n",
    "    \n",
    "    def get_csv(self,file):\n",
    "                \n",
    "        if file==1:\n",
    "            self.file='Accidents7904.csv'\n",
    "        elif file == 2:\n",
    "            self.file='Vehicles7904.csv'\n",
    "        elif file== 3:\n",
    "            self.file='Casualty7904.csv'\n",
    "            \n",
    "        self.file = os.path.join(self.root,self.file)\n",
    "        self.data = self.get_data()\n",
    "    def get_data(self):\n",
    " \n",
    "        data = pd.read_csv(self.file, delimiter=',',encoding='UTF-8-SIG',low_memory=False)\n",
    "             \n",
    "        return data\n",
    "    \n",
    "    def info_data(self):\n",
    "        print(\"Data_Describe\\n\",self.data.describe().T)\n",
    "        #Check encoding file\n",
    "        import chardet\n",
    "        with open(self.file, 'rb') as rawdata:\n",
    "            result = chardet.detect(rawdata.read(10000))\n",
    "        print(result)\n",
    "        \n",
    "    def \n",
    "       \n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "thrown-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prueba import data_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "private-wrong",
   "metadata": {},
   "outputs": [],
   "source": [
    "var1 = data_class()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "controversial-equipment",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<prueba.data_class at 0x1cda319bf70>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "unlikely-american",
   "metadata": {},
   "outputs": [],
   "source": [
    "var1.get_csv(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "genuine-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "var1.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "statistical-jurisdiction",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_Describe\n",
      "                                         count       mean        std  min  25%  \\\n",
      "Vehicle_Reference                   8264687.0   1.409508   0.687647  0.0  1.0   \n",
      "Casualty_Reference                  8264687.0   1.431801   1.461825  0.0  1.0   \n",
      "Casualty_Class                      8264687.0   1.599326   0.754204  1.0  1.0   \n",
      "Sex_of_Casualty                     8264687.0   1.397635   0.492329 -1.0  1.0   \n",
      "Age_Band_of_Casualty                8264687.0   5.603401   2.437791 -1.0  4.0   \n",
      "Casualty_Severity                   8264687.0   2.798114   0.435357  1.0  3.0   \n",
      "Pedestrian_Location                 8264687.0   0.855259   2.090907 -1.0  0.0   \n",
      "Pedestrian_Movement                 8264687.0   0.536895   1.612887 -1.0  0.0   \n",
      "Car_Passenger                       8264687.0   0.297970   0.615665 -1.0  0.0   \n",
      "Bus_or_Coach_Passenger              8264687.0   0.088092   0.555045 -1.0  0.0   \n",
      "Pedestrian_Road_Maintenance_Worker  8264687.0  -0.164345   0.370588 -1.0  0.0   \n",
      "Casualty_Type                       8264687.0  73.900321  49.425007 -1.0  2.0   \n",
      "Casualty_Home_Area_Type             8264687.0  -0.716329   0.792901 -1.0 -1.0   \n",
      "\n",
      "                                      50%    75%    max  \n",
      "Vehicle_Reference                     1.0    2.0  201.0  \n",
      "Casualty_Reference                    1.0    2.0  991.0  \n",
      "Casualty_Class                        1.0    2.0    3.0  \n",
      "Sex_of_Casualty                       1.0    2.0    2.0  \n",
      "Age_Band_of_Casualty                  6.0    7.0   11.0  \n",
      "Casualty_Severity                     3.0    3.0    3.0  \n",
      "Pedestrian_Location                   0.0    0.0   10.0  \n",
      "Pedestrian_Movement                   0.0    0.0    9.0  \n",
      "Car_Passenger                         0.0    0.0    2.0  \n",
      "Bus_or_Coach_Passenger                0.0    0.0    4.0  \n",
      "Pedestrian_Road_Maintenance_Worker    0.0    0.0    0.0  \n",
      "Casualty_Type                       109.0  109.0  113.0  \n",
      "Casualty_Home_Area_Type              -1.0   -1.0    3.0  \n",
      "{'encoding': 'UTF-8-SIG', 'confidence': 1.0, 'language': ''}\n"
     ]
    }
   ],
   "source": [
    "var1.info_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "original-wrong",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'var1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-2b8ed3483582>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mvar1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'var1' is not defined"
     ]
    }
   ],
   "source": [
    "var1.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "solved-dance",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ml_score():\n",
    "\n",
    "    \n",
    "    def __init__(self,data,root=\"../../\"):\n",
    "        self.root = \"../../\"\n",
    "        self.data=data\n",
    "        \n",
    "    def cat_num(self):\n",
    "        for i in self.data.columns:\n",
    "            if i == 'Age_of_Vehicle' or i == 'Engine_Capacity_(CC)':\n",
    "                self.data[i] = self.data[i].astype('int64')\n",
    "            else:\n",
    "                self.data[i] = self.data[i].astype('str')\n",
    "        return\n",
    "\n",
    "    def calculate_vif(self,X, thresh=5.0):\n",
    "        from statsmodels.stats.outliers_influence import variance_inflation_factor  \n",
    "        variables = list(range(X.shape[1]))\n",
    "        dropped = True\n",
    "        while dropped:\n",
    "            dropped = False\n",
    "            vif = [variance_inflation_factor(X.iloc[:, variables].values, ix)\n",
    "                   for ix in range(X.iloc[:, variables].shape[1])]\n",
    "\n",
    "            maxloc = vif.index(max(vif))\n",
    "            if max(vif) > thresh:\n",
    "                print('dropping \\'' + X.iloc[:, variables].columns[maxloc] +\n",
    "                      '\\' at index: ' + str(maxloc))\n",
    "                del variables[maxloc]\n",
    "                dropped = True\n",
    "\n",
    "        print('Remaining variables:')\n",
    "        print(X.columns[variables])\n",
    "        return X.iloc[:, variables]\n",
    "\n",
    "\n",
    "    def vtypes(self):\n",
    "        cat = self.data.select_dtypes('object').columns\n",
    "        num = self.data.select_dtypes('float64').columns\n",
    "        return cat,num\n",
    "\n",
    "\n",
    "    def lencoder(self):\n",
    "        lenc = LabelEncoder()\n",
    "        self.data[cat] = self.data[cat].apply(lenc.fit_transform)\n",
    "        self.data['Accident_Severity'] = lenc.fit_transform(self.data['Accident_Severity'])\n",
    "        return df_imbalanced\n",
    "\n",
    "\n",
    "    def target_features(self):\n",
    "        X = self.data.drop('Accident_Severity', axis=1)\n",
    "        y = self.data['Accident_Severity']\n",
    "        return X,y\n",
    "\n",
    "    def split(self,X,y):\n",
    "        from sklearn.model_selection import train_test_split\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recreational-beijing",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-rubber",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attractive-canal",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "combined-guyana",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "uniform-printing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting test0001.py\n"
     ]
    }
   ],
   "source": [
    "class modelling_score():\n",
    "    \n",
    "    from sklearn.pipeline import Pipeline\n",
    "    from sklearn.preprocessing import StandardScaler, OneHotEncoder,LabelEncoder\n",
    "    from sklearn.compose import ColumnTransformer\n",
    "\n",
    "    from sklearn.metrics import mean_squared_error, mean_absolute_error, \\\n",
    "                                explained_variance_score,recall_score,f1_score,precision_score,roc_curve,roc_auc_score,\\\n",
    "                                accuracy_score,confusion_matrix, classification_report\n",
    "\n",
    "    from sklearn.neighbors import KNeighborsClassifier\n",
    "    from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "    from sklearn.svm import LinearSVC,SVC\n",
    "\n",
    "    from sklearn.model_selection import learning_curve\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    from sklearn.model_selection import cross_val_score, RepeatedStratifiedKFold, train_test_split,cross_validate\n",
    "    from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "    from sklearn.ensemble import RandomForestClassifier,BaggingClassifier\n",
    "    from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "    \n",
    "    def __init__(self,data,X,y,num,cat):\n",
    "        self.data = data\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.num = num\n",
    "        self.cat = cat\n",
    "        \n",
    "    \n",
    "    def fit_pred_mod(self,select_model,folder,LogisticRegression):\n",
    "          #model selection \n",
    "        if select_model == 1:\n",
    "            model = LogisticRegression(multi_class= \"multinomial\",solver='lbfgs')\n",
    "        elif select_model == 2:\n",
    "            model = DecisionTreeClassifier()\n",
    "        elif select_model == 3:\n",
    "            model = RandomForestClassifier()\n",
    "        elif select_model == 4:\n",
    "            model = BaggingClassifier()\n",
    "        elif select_model == 5:\n",
    "            model = LinearSVC()\n",
    "        elif select_model == 6:\n",
    "            model = KNeighborsClassifier()\n",
    "        elif select_model == 7:\n",
    "            model = MLPClassifier()\n",
    "        if folder == 1:\n",
    "            folder = 'imb_reports'\n",
    "        elif folder == 2:\n",
    "            folder = 'bal_reports'\n",
    "        elif folder == 3:\n",
    "            folder = 'smote_reports'\n",
    "\n",
    "        numeric_features = self.num\n",
    "        categorical_features = self.cat\n",
    "        #Handling categorical and numerical data with Pipelines\n",
    "        numeric_transformer = Pipeline(steps=[\n",
    "        #('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', StandardScaler())])\n",
    "\n",
    "        #categorical_transformer = LabelEncoder()\n",
    "        categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "        categorical_transformer  = StandardScaler()\n",
    "        preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features),])\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "        clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "        ('classifier', model)])\n",
    "        clf.fit(X_train, y_train)\n",
    "        yhat = clf.predict(X_test)\n",
    "\n",
    "        eval_score(X_train, X_test, y_train, y_test, clf, yhat,select_model,folder)\n",
    "\n",
    "        return\n",
    "    \n",
    "\n",
    "\n",
    "def eval_score(X_train, X_test, y_train, y_test, classifier,yhat,select_model,folder):\n",
    "  #  classifier.fit(X_train, y_train)\n",
    "#    preds = classifier.predict(X_test)\n",
    "#    probs = classifier.predict_proba(X_test)\n",
    "    \n",
    "    if select_model == 1:\n",
    "        modelts = 'LogisticRegression' # no feature importance\n",
    "    elif select_model == 2:\n",
    "        modelts = 'DecisionTreeClassifier'\n",
    "    elif select_model == 3:\n",
    "        modelts = 'RandomForestClassifier'\n",
    "    elif select_model == 4:\n",
    "        modelts = 'BaggingClassifier' # no feature importance\n",
    "    elif select_model == 5:\n",
    "        modelts = 'LinearSVC' # no feature importance\n",
    "    elif select_model == 6:\n",
    "        modelts = 'KNeighborsClassifier' # no feature importance\n",
    "    elif select_model == 7:\n",
    "        modelts = 'MLPClassifier' # no feature importance\n",
    "          \n",
    "  \n",
    "    n_class = 3\n",
    "    print(\"model score: %.3f\" % classifier.score(X_test, y_test))\n",
    "    cr = classification_report(y_test, yhat)\n",
    "    print(cr)\n",
    "    \n",
    "    f = open(folder+'/report_'+modelts+'.txt', 'w')\n",
    "    f.write('Classification Report {}\\n\\n{}'.format(modelts ,cr))\n",
    "    f.close()\n",
    "    \n",
    "    if select_model in [1,2,3,4,6,7]:\n",
    "        # roc curve for classes\n",
    "        fpr = {}\n",
    "        tpr = {}\n",
    "        thresh ={}\n",
    "        probs = classifier.predict_proba(X_test)\n",
    "        for i in range(n_class):    \n",
    "            fpr[i], tpr[i], thresh[i] = roc_curve(y_test, probs[:,i], pos_label=i)\n",
    "        # plotting    \n",
    "        plt.plot(fpr[0], tpr[0], linestyle='--',color='green', label='Slight')\n",
    "        plt.plot(fpr[1], tpr[1], linestyle='--',color='orange', label='Serious')\n",
    "        plt.plot(fpr[2], tpr[2], linestyle='--',color='red', label='Fatal')\n",
    "        plt.title('Multiclass ROC curve')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive rate')\n",
    "        plt.legend(loc='best')\n",
    "        plt.savefig(folder+'/'+ modelts+'Multiclass ROC',dpi=300);\n",
    "        roc_auc_score(y_test, probs,multi_class='ovo', average='weighted')\n",
    "    #plotting matrix confusion\n",
    "    matrix = confusion_matrix(y_test, yhat)\n",
    "    dataframe = pd.DataFrame(matrix, index=['Fatal', 'Serious', 'Slight'], \n",
    "                            columns=['Fatal', 'Serious', 'Slight'])\n",
    "    # create heatmap\n",
    "    fig,ax = plt.subplots()\n",
    "    ax = sns.heatmap(dataframe, annot=True, cbar=None, cmap='Blues')\n",
    "    ax = plt.title('Confusion Matrix')\n",
    "    ax = plt.tight_layout(), plt.xlabel('True Values'), plt.ylabel('Predicted Values')\n",
    "    plt.show()\n",
    "    fig.savefig(folder+'/' + modelts +'Confusion Matrix',dpi=300);\n",
    "    \n",
    "    if select_model in [2,3]:\n",
    "    #features importance\n",
    "        fig,ax = plt.subplots()\n",
    "        feat_importances = pd.Series(classifier.steps[1][1].feature_importances_, index=features_col)\n",
    "        feat_importances.sort_values().plot(kind='barh', figsize=(10,5),ax=ax)\n",
    "        plt.xlabel('Relative Feature Importance with {}'.format(modelts));\n",
    "        plt.show();\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "solar-ability",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
