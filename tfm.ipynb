{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "cmap = cm.get_cmap\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "import io\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Check encoding file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import chardet\n",
    "with open(\"D:\\Descargas\\Stats19-Data1979-2004\\Accidents7904.csv\", 'rb') as rawdata:\n",
    "    result = chardet.detect(rawdata.read(10000))\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Import Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents=pd.read_csv('D:\\Descargas\\Stats19-Data1979-2004\\Accidents7904.csv',delimiter=',',encoding='UTF-8-SIG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Cleaning and pre process the data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Checking percentage of missing or NaN values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaN data: \\n \\n\",\" \\n \",accidents.isna().sum()/len(accidents),\"%\")\n",
    "print(\"\\n Missing or out of range data:\\n\",np.abs(accidents[accidents==-1].sum())/len(accidents),\"%\")\n",
    "#accidents.isna().sum().sum()/len(accidents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Drop the useless columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = ['Police_Force', 'Local_Authority_(District)', 'Local_Authority_(Highway)', \n",
    "             '1st_Road_Number', '2nd_Road_Number', 'Pedestrian_Crossing-Human_Control', \n",
    "             'Pedestrian_Crossing-Physical_Facilities','Did_Police_Officer_Attend_Scene_of_Accident',\n",
    "            'LSOA_of_Accident_Location','Longitude','Latitude','Urban_or_Rural_Area','Junction_Control','2nd_Road_Class','Special_Conditions_at_Site','Carriageway_Hazards','Junction_Detail']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.drop(labels=columns_to_drop,inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.isna().sum()/len(accidents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Values = -1 are missing data or values out of range\n",
    "# el resto el haremos drop ya que tiene unos porcentajes muy bajos y no nos afectarÃ¡n al anÃ¡lisis posterior.\n",
    "print(\"NaN data: \\n \\n\",\" \\n \",accidents.isna().sum()/len(accidents),\"%\")\n",
    "print(\"\\n Missing or out of range data:\\n\",np.abs(accidents[accidents==-1].sum())/len(accidents),\"%\")\n",
    "#accidents.isna().sum().sum()/len(accidents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Clean missing values =-1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the missing values = -1\n",
    "for i,k in enumerate(accidents):\n",
    "    accidents.drop(index=accidents[accidents[k] == -1].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accidents = accidents.to_csv('Descargas/Stats19-Data1979-2004/accidents_clean.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents['Date']=pd.to_datetime(accidents['Date'])\n",
    "accidents['Month']=accidents['Date'].dt.month\n",
    "accidents['Year']=accidents['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents['Accident_Index'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents['Hour']=  accidents['Time'].str[0:2]\n",
    "accidents['Hour'] = pd.to_numeric(accidents['Hour'])\n",
    "accidents = accidents.dropna(subset=['Hour'])\n",
    "accidents['Hour'] = accidents['Hour'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def daytime(hour):\n",
    "    if hour >= 5 and hour < 10:\n",
    "        return \"Commuting to work\"\n",
    "    elif hour >= 10 and hour < 15:\n",
    "        return \"Office hours\"\n",
    "    elif hour >= 15 and hour < 19:\n",
    "        return \"Commuting to home\"\n",
    "    elif hour >= 19 and hour < 23:\n",
    "        return \"Evening\"\n",
    "    else:\n",
    "        return \"Night\"\n",
    "accidents['Daytime'] = accidents['Hour'].apply(daytime)\n",
    "accidents[['Time', 'Hour', 'Daytime']].head(8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents['Daytime'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.head()\n",
    "print(accidents.shape)\n",
    "accidents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents['Accident_Severity'].replace([1,2,3],['Fatal','Serious','Slight'],inplace=True)\n",
    "accidents.Accident_Severity.value_counts(normalize=True).plot(kind='pie')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "days = ['Sunday', 'Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "accidents['Day_of_Week'].replace([1,2,3,4,5,6,7],days, inplace=True)\n",
    "accidents.Day_of_Week.value_counts(normalize=True).sort_values(ascending=True).plot(kind='bar',color='grey');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Put Motorway and A(M) in the same category\n",
    "accidents['1st_Road_Class'].replace([1,2,3,4,5,6],['Motorway','A(M)','A', 'B', 'C', 'Unclassified'],inplace=True)\n",
    "\n",
    "accidents['1st_Road_Class'] = accidents['1st_Road_Class'].replace('A(M)', 'Motorway')\n",
    "accidents['1st_Road_Class'].value_counts(normalize=True).plot(kind='bar',color='gold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents['Road_Type'].replace([1,2,3,6,7,9,12],['Roundabout','One way street','Dual carriageway','Single carriageway','Slip road','Unknown','One way street/Slip road'],inplace=True)\n",
    "accidents.Road_Type.value_counts(normalize=True).plot(kind='bar',color='gold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accidents['Junction_Detail'].replace([0,1,2,3,5,6,7,8,9],['Not at junction or within 20 metres',\n",
    "#                                                         'Roundabout', 'Mini-roundabout', 'T or staggered junction', 'Slip road','Crossroads',\n",
    "#                                                          'More than 4 arms (not roundabout)','Private drive or entrance','Other junction'],inplace=True)\n",
    "#accidents.Junction_Detail.value_counts(normalize=True).plot(kind='bar',color='gold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.Light_Conditions = accidents.Light_Conditions.replace([1,4,5,6,7], \n",
    "                                                      ['Daylight', \n",
    "                                                       'Darkness - lights lit', \n",
    "                                                       'Darkness - lights unlit', \n",
    "                                                       'Darkness - no lighting', \n",
    "                                                       'Darkness - lighting unknown'])\n",
    "\n",
    "\n",
    "accidents.Light_Conditions.value_counts(normalize=True).plot(kind='bar',color='gold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.Weather_Conditions = accidents.Weather_Conditions.replace([1,2,3,4,5,6,7,8,9], \n",
    "                                                                ['Fine no high winds', \n",
    "                                                                 'Raining no high winds', \n",
    "                                                                 'Snowing no high winds', \n",
    "                                                                 'Fine + high winds', \n",
    "                                                                 'Raining + high winds', \n",
    "                                                                 'Snowing + high winds', \n",
    "                                                                 'Fog or mist', 'Other', 'Unknown', \n",
    "                                                                 ])\n",
    "accidents.Weather_Conditions.value_counts(normalize=True).plot(kind='bar',color='gold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.Road_Surface_Conditions = accidents.Road_Surface_Conditions.replace([1,2,3,4,5,6,7], \n",
    "                                                                                    ['Dry', \n",
    "                                                                                     'Wet or damp', \n",
    "                                                                                     'Snow', \n",
    "                                                                                     'Frost or ice', \n",
    "                                                                                     'Flood over 3cm. deep',\n",
    "                                                                                     'Oil or diesel',\n",
    "                                                                                     'Mud'])\n",
    "accidents.Road_Surface_Conditions.value_counts(normalize=True).plot(kind='bar',color='gold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "accidents.Special_Conditions_at_Site = \\\n",
    "accidents.Special_Conditions_at_Site.replace([0,1,2,3,4,5,6,7,-1],  \n",
    "                                                ['None', 'Auto traffic singal - out', \n",
    "                                                 'Auto signal part defective', \n",
    "                                                 'Road sign or marking defective or obscured', \n",
    "                                                 'Roadworks', 'Road surface defective', \n",
    "                                                 'Oil or diesel', 'Mud','None'])\n",
    "accidents.Special_Conditions_at_Site.value_counts(normalize=True).plot(kind='barh',color='gold');\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "accidents.Carriageway_Hazards.replace([0,1,2,3],  \n",
    "                                                ['None', 'Vehicle load on road', \n",
    "                                                 'Other object on road', \n",
    "                                                 'Previous accident'\n",
    "])\n",
    "\n",
    "accidents.Carriageway_Hazards.value_counts(normalize=True).plot(kind='barh',color='gold');\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents['Month'] = accidents['Month'].astype(int)\n",
    "\n",
    "accidents['Month'] = accidents['Month'].replace([1,2,3,4,5,6,7,8,9,10,11,12],['January', 'February', \n",
    "                                                 'March','April', 'May','June',\n",
    "                                                 'July', 'August', 'September',\n",
    "                                                'October','November','December'\n",
    "])\n",
    "\n",
    "accidents['Year'] = accidents['Year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dark_or_not(value):\n",
    "    if value == 'Daylight':\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return 'No'\n",
    "accidents['Daylight?'] = accidents['Light_Conditions'].apply(dark_or_not)\n",
    "accidents['Daylight?'].value_counts().plot(kind='bar',color='coral');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.Weather_Conditions.value_counts()\n",
    "\n",
    "def good_weather(value):\n",
    "    if value == 'Fine no high winds':\n",
    "        return 'Yes'\n",
    "    else:\n",
    "        return 'No'\n",
    "accidents['Good_weather_conditions'] =  accidents.Weather_Conditions.apply(good_weather)\n",
    "accidents['Good_weather_conditions'].value_counts().plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = accidents.groupby('Year')\\\n",
    ".agg({'Accident_Index':'count', 'Number_of_Vehicles': 'sum','Number_of_Casualties': 'sum','Accident_Severity':'count'})\\\n",
    ".reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "mport altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "source = df1\n",
    "\n",
    "alt.Chart(source).mark_bar().encode(\n",
    "    x='Year:O',\n",
    "    y=\"Accident_Index:Q\",    # The highlight will be set on the result of a conditional statement\n",
    "    color=alt.condition(\n",
    "        alt.datum.Year == 1989,  # If the year is 1810 this test returns True,\n",
    "        alt.value('blue'),     # which sets the bar orange.\n",
    "        alt.value('steelblue')   # And if it's not true it sets the bar steelblue.\n",
    "        \n",
    "    )\n",
    ").properties(\n",
    "    width=600,title=\"RelaciÃ³n peso del cerebro y del cuerpo\"\n",
    ").interactive()\n",
    "    \n",
    "\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizarmos resample de la fecha para ponerla como Ã­ndice y agruparla por mes, de esta manera\n",
    "# podemos generar el grÃ¡fico con el total mensual y luego poder calcular una media con una ventana=12\n",
    "# que son lso meses del aÃ±o.\n",
    "\n",
    "sns.set_style('white')\n",
    "fig, ax = plt.subplots(figsize=(28,10))\n",
    "\n",
    "accidents.set_index('Date').resample('M').size().plot(label='Total por Mes', color='grey', ax=ax)\n",
    "accidents.set_index('Date').resample('M').size().rolling(window=12).mean()\\\n",
    "                           .plot(color='lightgreen', linewidth=5, label='Media mensual 12 meses', ax=ax)\n",
    "\n",
    "ax.set_title('Accidents per Month', fontsize=25, fontweight='bold')\n",
    "ax.set(ylabel='Total Count\\n', xlabel='')\n",
    "ax.legend()\n",
    "\n",
    "sns.despine(ax=ax, top=True, right=True, left=True, bottom=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = accidents.groupby(['Year'])\\\n",
    ".agg({'Accident_Index':'count', 'Number_of_Vehicles': 'sum','Number_of_Casualties': 'sum',})\\\n",
    ".reset_index()\n",
    "#-------------------------\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "x = df1.Year\n",
    "labels = df1.Year\n",
    "width = 0.5\n",
    "Accidentcounts = df1['Accident_Index']\n",
    "Casualtycounts =  df1['Number_of_Casualties']\n",
    "fig,ax =  plt.subplots(figsize=(18,7))\n",
    "\n",
    "bar1 = ax.bar(x - width/2, Accidentcounts, width, label='Accident counts', color = 'lightgrey');\n",
    "bar2 = ax.bar(x + width/2, Casualtycounts, width, label='Casualty counts', color = 'lightskyblue');\n",
    "bar1[10].set_color('orange')\n",
    "bar2[10].set_color('purple')\n",
    "ax.set_title('\\nAccidents / Casualties \\n per Year\\n', fontsize=25, fontweight='bold')\n",
    "ax.set_xlabel('Year',fontsize=15)\n",
    "ax.set_ylabel('Total counts\\n',fontsize=15)\n",
    "ax.legend()\n",
    "ax.set_xticks(x)\n",
    "sns.despine(ax=ax, top=True, right=True, left=True, bottom=False);\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# En quÃ© meses hay mÃ¡s accidentes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = accidents.groupby(['Month'])['Accident_Index'].count().reset_index()\n",
    "\n",
    "months = ['January', 'February','March','April', 'May','June','July','August', 'September','October','November','December']\n",
    "df2['Month'] = pd.Categorical(df2['Month'], categories=months, ordered=True)\n",
    "#df2.sort_values(...)  # same as you have now; can use inplace=True\n",
    "df2 = df2.sort_values(by='Month')\n",
    "\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "x = df2['Month']\n",
    "y = df2['Accident_Index']\n",
    "fig, ax =  plt.subplots(figsize=(15,8))\n",
    "\n",
    "ax.plot(x,y,color='lightskyblue',linewidth=4)\n",
    "ax.set_title('Accidents per Month', fontsize=25, fontweight='bold')\n",
    "ax.set_xlabel('\\n Month',fontsize=15)\n",
    "ax.set_ylabel('Total Count\\n',fontsize=15)\n",
    "sns.despine(ax=ax, top=True, right=True, left=True, bottom=False);\n",
    "plt.show();\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas_ratio= accidents.groupby(['Year'])['Number_of_Casualties'].sum().reset_index()\n",
    "\n",
    "cas_ratio['Casualty_Ratio'] = cas_ratio['Number_of_Casualties'].div(cas_ratio['Number_of_Casualties'].sum())\n",
    "\n",
    "\n",
    "veh_ratio = accidents.groupby(['Year'])['Number_of_Vehicles'].sum().reset_index()\n",
    "\n",
    "veh_ratio['Vehicle_Ratio'] = veh_ratio['Number_of_Vehicles'].div(veh_ratio['Number_of_Vehicles'].sum())\n",
    "\n",
    "#df_census = df_census.groupby('NAME')[['NAME', 'TOTAL_POPULATION']].sum().reset_index()\n",
    "\n",
    "# Standardizing the values so as to conform the population ratio\n",
    "#df_census['Population_Ratio'] = df_census['TOTAL_POPULATION'].div(df_census['TOTAL_POPULATION'].sum())\n",
    "df2\n",
    "merged = pd.merge(veh_ratio,cas_ratio,on='Year',how='inner')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = accidents.groupby(['Day_of_Week'])['Accident_Index'].count().sort_values(ascending=False).reset_index()\n",
    "df3\n",
    "days = ['Sunday', 'Monday', 'Tuesday','Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "df3['Day_of_Week'] = pd.Categorical(df3['Day_of_Week'], categories=days, ordered=True)\n",
    "\n",
    "df3 = df3.sort_values(by='Day_of_Week',ascending=True)\n",
    "df3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QuÃ© dia de la semana hay mÃ¡s accidentes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.set_style('white')\n",
    "fig, ax = plt.subplots(figsize=(10,5))\n",
    "\n",
    "barlist = plt.bar(df3['Day_of_Week'],df3['Accident_Index'],color='lightgreen')\n",
    "barlist[5].set_color('r')\n",
    "\n",
    "ax.set_title('\\nAccidents per Weekday\\n', fontsize=14, fontweight='bold')\n",
    "ax.set(ylabel='\\nTotal Counts',xlabel='\\nWeekDay')\n",
    "\n",
    "\n",
    "# remove all spines\n",
    "sns.despine(ax=ax, top=True, right=True, left=True, bottom=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mapa de calor Weekday vs Daytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = accidents.groupby(['Day_of_Week','Daytime'])['Accident_Index'].count().reset_index()\n",
    "\n",
    "\n",
    "days = ['Sunday', 'Monday', 'Tuesday','Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "df4['Day_of_Week'] = pd.Categorical(df4['Day_of_Week'], categories=days, ordered=True)\n",
    "df4 = df4.pivot(index='Day_of_Week', columns='Daytime', values='Accident_Index')\n",
    "df4.sort_values(by='Day_of_Week',ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap = cm.get_cmap('PuBu')\n",
    "plt.figure(figsize=(15,10))\n",
    "weekday = ['Sunday', 'Monday', 'Tuesday','Wednesday', 'Thursday', 'Friday', 'Saturday']\n",
    "number=[1,2,3,4,5,6,7]\n",
    "sns.heatmap(df4, cmap=cmap)\n",
    "plt.title('\\nAccidents by Weekday and Daytime\\n', fontsize=14, fontweight='bold');\n",
    "plt.yticks(rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = accidents.groupby(['Day_of_Week','Accident_Severity','Daylight?'])['Number_of_Casualties'].sum().reset_index()\n",
    "dayweek = ['Sunday','Monday','Tuesday','Wednesday','Thursday','Friday','Saturday']\n",
    "df5['Day_of_Week'] = pd.Categorical(df5['Day_of_Week'], categories=dayweek, ordered=True)\n",
    "#df2.sort_values(...)  # same as you have now; can use inplace=True\n",
    "df5 = df5.sort_values(by='Day_of_Week',ascending=True)\n",
    "df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.head()\n",
    "\n",
    "import altair as alt\n",
    "from vega_datasets import data\n",
    "\n",
    "source = df5\n",
    "\n",
    "alt.Chart(source).mark_circle().encode(\n",
    "    alt.X('Number_of_Casualties',scale=alt.Scale(zero=False)),\n",
    "    alt.Y('Day_of_Week',scale=alt.Scale(zero=False, padding=1)),\n",
    "    color='Accident_Severity',\n",
    "    size='Daylight?'\n",
    ").properties(\n",
    "    width=1000,\n",
    "    height=500).interactive()\n",
    "#por mas que lo intento no me ordena por weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('white')\n",
    "fig, ax = plt.subplots(figsize=(15,8))\n",
    "\n",
    "\n",
    "accidents.Hour.hist(bins=24, ax=ax, color='lightpink')\n",
    "ax.set_title('\\nAccidents by Time\\n', fontsize=14, fontweight='bold')\n",
    "ax.set(xlabel='\\nHour of the Day', ylabel='\\n Total Count of Accidents')\n",
    "\n",
    "# remove all spines\n",
    "sns.despine(top=True, right=True, left=True, bottom=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accident Severity vs Daytime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df6 = accidents.groupby(['Daytime','Accident_Severity'])['Accident_Index'].count().reset_index()\n",
    "fig, ax = plt.subplots(1, figsize=(30,10))\n",
    "accidents.groupby('Daytime')['Accident_Severity'].value_counts(normalize=True).unstack().plot(kind='barh', stacked=True, color=['red', 'orange', 'lightgrey'], ax=ax)\n",
    "ax.legend(loc='best', bbox_to_anchor=(1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(30,10))\n",
    "\n",
    "accidents.groupby('Speed_limit')['Accident_Severity'].value_counts(normalize=True).unstack().plot(kind='bar', stacked=True, color=['black', 'orange', 'lightgrey'], ax=ax)\n",
    "\n",
    "ax.legend(loc='best', bbox_to_anchor=(1,1))\n",
    "\n",
    "ax.set_title('Accident severity proportions at different speed limits')\n",
    "ax.set_xlabel('Road speed limit (mph)',rotation=0)\n",
    "ax.set_ylabel('Proportion of accidents')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HIST DE LAS VARIABLES NUMERICAS\n",
    "\n",
    "\n",
    "accidents.hist(figsize=(15,12));\n",
    "plt.tight_layout()\n",
    "#PARTE DE CONCATENAR LOS DATAFRAMES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VEHICLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "cmap = cm.get_cmap\n",
    "import seaborn as sns\n",
    "pd.set_option('display.max_columns', None)\n",
    "%matplotlib inline\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veh=pd.read_csv('D:/Descargas/Stats19-Data1979-2004/Vehicles7904.csv',delimiter=',',encoding='UTF-8-SIG',usecols=[\n",
    "    'Acc_Index', 'Vehicle_Reference', 'Vehicle_Type',\n",
    "    'Was_Vehicle_Left_Hand_Drive?','Sex_of_Driver',\n",
    "    'Age_Band_of_Driver','Engine_Capacity_(CC)', \n",
    "    'Propulsion_Code', 'Age_of_Vehicle'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaN data: \\n \\n\",\" \\n \",veh.isna().sum()/len(veh),\"%\")\n",
    "print(\"\\n Missing or out of range data:\\n\",np.abs(veh[veh==-1].sum())/len(veh),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing or out of range values\n",
    "veh.drop(labels='Was_Vehicle_Left_Hand_Drive?',inplace=True,axis=1)\n",
    "veh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop missing or out of range values\n",
    "for i,k in enumerate(veh):\n",
    "    veh.drop(index=veh[veh[k] == -1].index, inplace=True,axis=1)\n",
    "\n",
    "#veh.drop(index=veh[veh['Sex_of_Driver'] == -1].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veh.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veh.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veh.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CASUALTIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cas=pd.read_csv('D:/Descargas/Stats19-Data1979-2004/Casualty7904.csv',delimiter=',',encoding='UTF-8-SIG')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaN data: \\n \\n\",\" \\n \",veh.isna().sum()/len(veh),\"%\")\n",
    "print(\"\\n Missing or out of range data:\\n\",np.abs(veh[veh==-1].sum())/len(veh),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cas.describe().T)\n",
    "cas.shape\n",
    "cas.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%who\n",
    "df_merge = pd.merge(cas,veh,how='inner',on='Acc_Index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del veh,cas\n",
    "df_merge.columns\n",
    "df_merge.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_merge.shape)\n",
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"NaN data: \\n \\n\",\" \\n \",df_merge.isna().sum()/len(df_merge),\"%\")\n",
    "print(\"\\n Missing or out of range data:\\n\",np.abs(df_merge[df_merge==-1].sum())/len(df_merge),\"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.drop(labels=['Casualty_Home_Area_Type','Pedestrian_Road_Maintenance_Worker','Pedestrian_Location',\n",
    "              'Casualty_Class','Vehicle_Reference_y','Vehicle_Reference_x','Casualty_Home_Area_Type',\n",
    "              'Pedestrian_Road_Maintenance_Worker','Car_Passenger','Pedestrian_Movement','Pedestrian_Location',\n",
    "                'Casualty_Severity','Casualty_Reference','Bus_or_Coach_Passenger'],inplace=True,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,k in enumerate(df_merge):\n",
    "    df_merge.drop(index=df_merge[df_merge[k] == -1].index, inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unknown values of Sex_of_Driver\n",
    "df_merge.drop(index=df_merge[df_merge['Sex_of_Driver'] == 3].index, inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.Sex_of_Casualty = df_merge.Sex_of_Casualty.replace([1,2],['Male','Female'])\n",
    "\n",
    "df_merge.Age_Band_of_Casualty = df_merge.Age_Band_of_Casualty.replace([1,2,3,4,5,6,7,8,9,10,11],['0 - 5','6 - 10','11 - 15',\n",
    "                                                                                                 '16 - 20','21 - 25','26 - 35',\n",
    "                                                                                              '36 - 45','46 - 55','56 - 65',\n",
    "                                                                                              '66 - 75','Over 75'\n",
    "                                                                                                ])\n",
    "\n",
    "values1=['Pedestrian',\n",
    "'Cyclist',\n",
    "'Motorcycle 50cc and under rider or passenger',\n",
    "'Motorcycle 125cc and under rider or passenger',\n",
    "'Motorcycle over 125cc and up to 500cc rider or  passenger',\n",
    "'Motorcycle over 500cc rider or passenger',\n",
    "'Taxi/Private hire car occupant',\n",
    "'Car occupant',\n",
    "'Minibus (8 - 16 passenger seats) occupant',\n",
    "'Bus or coach occupant (17 or more pass seats)',\n",
    "'Horse rider',\n",
    "'Agricultural vehicle occupant',\n",
    "'Tram occupant',\n",
    "'Van / Goods vehicle (3.5 tonnes mgw or under) occupant',\n",
    "'Goods vehicle (over 3.5t. and under 7.5t.) occupant',\n",
    "'Goods vehicle (7.5 tonnes mgw and over) occupant',\n",
    "'Mobility scooter rider',\n",
    "'Electric motorcycle rider or passenger',\n",
    "'Other vehicle occupant',\n",
    "'Motorcycle - unknown cc rider or passenger',\n",
    "'Goods vehicle (unknown weight) occupant',\n",
    "'Motorcycle - Scooter rider or passenger',\n",
    "'Motorcycle rider or passenger',\n",
    "'Motorcycle - Combination rider or passenger',\n",
    "'Motorcycle over 125cc rider or passenger',\n",
    "'Taxi (excluding private hire cars) occupant',\n",
    "'Car occupant (including private hire cars)',\n",
    "'Minibus/Motor caravan occupant',\n",
    "'Goods vehicle (over 3.5 tonnes) occupant']\n",
    "values2 = [0,1,2,3,4,5,8,9,10,11,16,17,18,19,\n",
    "20,21,22,23,90,97,98,103,104,105,\n",
    "106,108,109,110,113]\n",
    "\n",
    "values3 = [1,2,3,10,11,17,19,20,\n",
    "21,90,103,104,105,\n",
    "106,108,109,110,113]\n",
    "\n",
    "values4 = ['Pedal cycle',\n",
    "'Motorcycle 50cc and under',\n",
    "'Motorcycle 125cc and under',\n",
    "'Minibus (8 - 16 passenger seats)',\n",
    "'Bus or coach (17 or more pass seats)',\n",
    "'Agricultural vehicle',\n",
    "'Van / Goods 3.5 tonnes mgw or under',\n",
    "'Goods over 3.5t. and under 7.5t',\n",
    "'Goods 7.5 tonnes mgw and over',\n",
    "'Other vehicle',\n",
    "'Motorcycle - Scooter',\n",
    "'Motorcycle',\n",
    "'Motorcycle - Combination',\n",
    "'Motorcycle over 125cc',\n",
    "'Taxi (excluding private hire cars)',\n",
    "'Car (including private hire cars)',\n",
    "'Minibus/Motor caravan',\n",
    "'Goods vehicle over 3.5 tonnes']\n",
    "\n",
    "\n",
    "\n",
    "df_merge.Casualty_Type = df_merge.Casualty_Type.replace(values2,values1)\n",
    "\n",
    "\n",
    "df_merge.Vehicle_Type = df_merge.Vehicle_Type.replace(values3,values4)\n",
    "\n",
    "df_merge.Sex_of_Driver = df_merge.Sex_of_Driver.replace([1,2],['Male','Female'])\n",
    "\n",
    "df_merge.Age_Band_of_Driver = df_merge.Age_Band_of_Driver.replace([1,2,3,4,5,6,7,8,9,10,11],['0 - 5','6 - 10','11 - 15',\n",
    "                                                                                                 '16 - 20','21 - 25','26 - 35',\n",
    "                                                                                              '36 - 45','46 - 55','56 - 65',\n",
    "                                                                                              '66 - 75','Over 75'\n",
    "                                                                                                ])\n",
    "#df_merge.Engine_Capacity_(CC) = df_merge.Engine_Capacity_(CC).replace([1,2],['Male','Female']) -->drop column\n",
    "\n",
    "df_merge.Propulsion_Code = df_merge.Propulsion_Code.replace([1,2,4,5,6,7,8,9],['Petrol',\n",
    "                                                                    'Heavy oil',\n",
    "                                                                    'Steam',\n",
    "                                                                    'Gas',\n",
    "                                                                    'Petrol/Gas (LPG)',\n",
    "                                                                    'Gas/Bi-fuel',\n",
    "                                                                    'Hybrid electric',\n",
    "                                                                    'Fuel cells'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_sex_driver = df_merge.groupby(['Age_Band_of_Driver','Sex_of_Driver']).size().reset_index()\n",
    "\n",
    "female = all_sex_driver[all_sex_driver['Sex_of_Driver'] == 'Female']\n",
    "male = all_sex_driver[all_sex_driver['Sex_of_Driver'] == 'Male']\n",
    "male['percentage'] = (male[0]/male[0].sum())*100\n",
    "female = all_sex_driver[all_sex_driver['Sex_of_Driver'] == 'Female']\n",
    "female['percentage'] = (female[0]/female[0].sum())*100\n",
    "female['percentage']=female['percentage'].astype(str)\n",
    "male['percentage']=male['percentage'].astype(str)\n",
    "female['percentage'] = female['percentage'].str[:4]+'%'\n",
    "male['percentage'] = male['percentage'].str[:4]+'%'\n",
    "\n",
    "\n",
    "all_sex_casualty = df_merge.groupby(['Age_Band_of_Casualty','Sex_of_Casualty'])['Acc_Index'].count().reset_index()\n",
    "female_cs = all_sex_casualty[all_sex_casualty['Sex_of_Casualty'] == 'Female']\n",
    "male_cs = all_sex_casualty[all_sex_casualty['Sex_of_Casualty'] == 'Male']\n",
    "\n",
    "female_cs['Percentage'] = (female_cs['Acc_Index']/(female_cs['Acc_Index'].sum())*100).astype(str).str[:4]+'%'\n",
    "male_cs['Percentage'] = (male_cs['Acc_Index']/(male_cs['Acc_Index'].sum())*100).astype(str).str[:4]+'%'\n",
    "gender_driver =  pd.concat([male,female])\n",
    "gender_casualty = pd.concat([male_cs,female_cs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#FALTA PARSEAR LO DE LOS RANGOS DE EDAD EN EL EJE Y\n",
    "fig, ax = plt.subplots(1, figsize=(15,10))\n",
    "df_merge.groupby('Age_Band_of_Driver')['Sex_of_Driver'].value_counts(normalize=True).unstack().plot(kind='barh', stacked=False, color=['grey', 'orange'], ax=ax)\n",
    "ax.legend(loc='best', bbox_to_anchor=(1,1),labels=['Male','Female'])\n",
    "\n",
    "\n",
    "'''\n",
    "''''''\n",
    "from plotly.subplots import make_subplots\n",
    "import plotly.graph_objects as go\n",
    "fig = make_subplots(1,1)\n",
    "import plotly.express as px\n",
    "\n",
    "fig1 = px.sunburst(gender_driver, path=['Sex_of_Driver','Age_Band_of_Driver','percentage'], color='Sex_of_Driver')\n",
    "fig1.update_layout(height=600, width=600, title_text=\"Age_Band_of_Driver vs Sex\")\n",
    "fig1.show()\n",
    "#PORCENTAJE DRIVERS IMPLICADOS\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.head()\n",
    "prueba = df_merge['Age_Band_of_Casualty'].sort_values().reset_index()\n",
    "import plotly.express as px\n",
    "fig2 = px.histogram(prueba, x=\"Age_Band_of_Casualty\")\n",
    "fig2.update_layout(height=700, width=700, title_text=\"Age_Band_of_Casualty\")\n",
    "fig2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_merge.Engine_Capacity_(CC) = df_merge.Engine_Capacity_(CC).replace([1,2],['Male','Female']) -->drop column\n",
    "veh_type = df_merge.groupby(['Vehicle_Type','Sex_of_Driver'])['Acc_Index'].count().reset_index()\n",
    "veh_type['Percentage'] = (veh_type['Acc_Index']/veh_type['Acc_Index'].sum()*100).sort_values(ascending=True).astype(str).str[:4]+'%'\n",
    "\n",
    "veh_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "cmap = cm.get_cmap\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder,LabelEncoder\n",
    "from sklearn.model_selection import train_test_split,cross_validate\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, \\\n",
    "explained_variance_score,recall_score,f1_score,precision_score,roc_curve,roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression  #regresiÃ³n logistica en clasificaciÃ³n\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa = pd.read_csv('D:\\Descargas\\Stats19-Data1979-2004\\Accidents7904.csv',delimiter=',',encoding='UTF-8-SIG',index_col=0,nrows=40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Location_Easting_OSGR</th>\n",
       "      <th>Location_Northing_OSGR</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Police_Force</th>\n",
       "      <th>Accident_Severity</th>\n",
       "      <th>Number_of_Vehicles</th>\n",
       "      <th>Number_of_Casualties</th>\n",
       "      <th>Date</th>\n",
       "      <th>Day_of_Week</th>\n",
       "      <th>...</th>\n",
       "      <th>Pedestrian_Crossing-Human_Control</th>\n",
       "      <th>Pedestrian_Crossing-Physical_Facilities</th>\n",
       "      <th>Light_Conditions</th>\n",
       "      <th>Weather_Conditions</th>\n",
       "      <th>Road_Surface_Conditions</th>\n",
       "      <th>Special_Conditions_at_Site</th>\n",
       "      <th>Carriageway_Hazards</th>\n",
       "      <th>Urban_or_Rural_Area</th>\n",
       "      <th>Did_Police_Officer_Attend_Scene_of_Accident</th>\n",
       "      <th>LSOA_of_Accident_Location</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accident_Index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>197901A11AD14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>18/01/1979</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197901A1BAW34</th>\n",
       "      <td>198460.0</td>\n",
       "      <td>894000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>01/01/1979</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197901A1BFD77</th>\n",
       "      <td>406380.0</td>\n",
       "      <td>307000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>01/01/1979</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197901A1BGC20</th>\n",
       "      <td>281680.0</td>\n",
       "      <td>440000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>01/01/1979</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197901A1BGF95</th>\n",
       "      <td>153960.0</td>\n",
       "      <td>795000.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>01/01/1979</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                Location_Easting_OSGR  Location_Northing_OSGR  Longitude  \\\n",
       "Accident_Index                                                             \n",
       "197901A11AD14                     NaN                     NaN        NaN   \n",
       "197901A1BAW34                198460.0                894000.0        NaN   \n",
       "197901A1BFD77                406380.0                307000.0        NaN   \n",
       "197901A1BGC20                281680.0                440000.0        NaN   \n",
       "197901A1BGF95                153960.0                795000.0        NaN   \n",
       "\n",
       "                Latitude  Police_Force  Accident_Severity  Number_of_Vehicles  \\\n",
       "Accident_Index                                                                  \n",
       "197901A11AD14        NaN             1                  3                   2   \n",
       "197901A1BAW34        NaN             1                  3                   1   \n",
       "197901A1BFD77        NaN             1                  3                   2   \n",
       "197901A1BGC20        NaN             1                  3                   2   \n",
       "197901A1BGF95        NaN             1                  2                   2   \n",
       "\n",
       "                Number_of_Casualties        Date  Day_of_Week  ...  \\\n",
       "Accident_Index                                                 ...   \n",
       "197901A11AD14                      1  18/01/1979            5  ...   \n",
       "197901A1BAW34                      1  01/01/1979            2  ...   \n",
       "197901A1BFD77                      3  01/01/1979            2  ...   \n",
       "197901A1BGC20                      2  01/01/1979            2  ...   \n",
       "197901A1BGF95                      1  01/01/1979            2  ...   \n",
       "\n",
       "               Pedestrian_Crossing-Human_Control  \\\n",
       "Accident_Index                                     \n",
       "197901A11AD14                                 -1   \n",
       "197901A1BAW34                                 -1   \n",
       "197901A1BFD77                                 -1   \n",
       "197901A1BGC20                                 -1   \n",
       "197901A1BGF95                                 -1   \n",
       "\n",
       "                Pedestrian_Crossing-Physical_Facilities  Light_Conditions  \\\n",
       "Accident_Index                                                              \n",
       "197901A11AD14                                        -1                 1   \n",
       "197901A1BAW34                                        -1                 4   \n",
       "197901A1BFD77                                        -1                 4   \n",
       "197901A1BGC20                                        -1                 4   \n",
       "197901A1BGF95                                        -1                 4   \n",
       "\n",
       "                Weather_Conditions  Road_Surface_Conditions  \\\n",
       "Accident_Index                                                \n",
       "197901A11AD14                    8                        1   \n",
       "197901A1BAW34                    8                        3   \n",
       "197901A1BFD77                    8                        3   \n",
       "197901A1BGC20                    8                        3   \n",
       "197901A1BGF95                    3                        3   \n",
       "\n",
       "                Special_Conditions_at_Site  Carriageway_Hazards  \\\n",
       "Accident_Index                                                    \n",
       "197901A11AD14                           -1                    0   \n",
       "197901A1BAW34                           -1                    0   \n",
       "197901A1BFD77                           -1                    0   \n",
       "197901A1BGC20                           -1                    0   \n",
       "197901A1BGF95                           -1                    0   \n",
       "\n",
       "                Urban_or_Rural_Area  \\\n",
       "Accident_Index                        \n",
       "197901A11AD14                    -1   \n",
       "197901A1BAW34                    -1   \n",
       "197901A1BFD77                    -1   \n",
       "197901A1BGC20                    -1   \n",
       "197901A1BGF95                    -1   \n",
       "\n",
       "                Did_Police_Officer_Attend_Scene_of_Accident  \\\n",
       "Accident_Index                                                \n",
       "197901A11AD14                                            -1   \n",
       "197901A1BAW34                                            -1   \n",
       "197901A1BFD77                                            -1   \n",
       "197901A1BGC20                                            -1   \n",
       "197901A1BGF95                                            -1   \n",
       "\n",
       "                LSOA_of_Accident_Location  \n",
       "Accident_Index                             \n",
       "197901A11AD14                         NaN  \n",
       "197901A1BAW34                         NaN  \n",
       "197901A1BFD77                         NaN  \n",
       "197901A1BGC20                         NaN  \n",
       "197901A1BGF95                         NaN  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 31)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location_Easting_OSGR                          float64\n",
       "Location_Northing_OSGR                         float64\n",
       "Longitude                                      float64\n",
       "Latitude                                       float64\n",
       "Police_Force                                     int64\n",
       "Accident_Severity                                int64\n",
       "Number_of_Vehicles                               int64\n",
       "Number_of_Casualties                             int64\n",
       "Date                                            object\n",
       "Day_of_Week                                      int64\n",
       "Time                                            object\n",
       "Local_Authority_(District)                       int64\n",
       "Local_Authority_(Highway)                        int64\n",
       "1st_Road_Class                                   int64\n",
       "1st_Road_Number                                  int64\n",
       "Road_Type                                        int64\n",
       "Speed_limit                                      int64\n",
       "Junction_Detail                                  int64\n",
       "Junction_Control                                 int64\n",
       "2nd_Road_Class                                   int64\n",
       "2nd_Road_Number                                  int64\n",
       "Pedestrian_Crossing-Human_Control                int64\n",
       "Pedestrian_Crossing-Physical_Facilities          int64\n",
       "Light_Conditions                                 int64\n",
       "Weather_Conditions                               int64\n",
       "Road_Surface_Conditions                          int64\n",
       "Special_Conditions_at_Site                       int64\n",
       "Carriageway_Hazards                              int64\n",
       "Urban_or_Rural_Area                              int64\n",
       "Did_Police_Officer_Attend_Scene_of_Accident      int64\n",
       "LSOA_of_Accident_Location                      float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Convert categorical variables to str**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location_Easting_OSGR                          0.004150\n",
       "Location_Northing_OSGR                         0.004150\n",
       "Longitude                                      1.000000\n",
       "Latitude                                       1.000000\n",
       "Police_Force                                   0.000000\n",
       "Accident_Severity                              0.000000\n",
       "Number_of_Vehicles                             0.000000\n",
       "Number_of_Casualties                           0.000000\n",
       "Date                                           0.000000\n",
       "Day_of_Week                                    0.000000\n",
       "Time                                           0.000325\n",
       "Local_Authority_(District)                     0.000000\n",
       "Local_Authority_(Highway)                      0.000000\n",
       "1st_Road_Class                                 0.000000\n",
       "1st_Road_Number                                0.000000\n",
       "Road_Type                                      0.000000\n",
       "Speed_limit                                    0.000000\n",
       "Junction_Detail                                0.000000\n",
       "Junction_Control                               0.000000\n",
       "2nd_Road_Class                                 0.000000\n",
       "2nd_Road_Number                                0.000000\n",
       "Pedestrian_Crossing-Human_Control              0.000000\n",
       "Pedestrian_Crossing-Physical_Facilities        0.000000\n",
       "Light_Conditions                               0.000000\n",
       "Weather_Conditions                             0.000000\n",
       "Road_Surface_Conditions                        0.000000\n",
       "Special_Conditions_at_Site                     0.000000\n",
       "Carriageway_Hazards                            0.000000\n",
       "Urban_or_Rural_Area                            0.000000\n",
       "Did_Police_Officer_Attend_Scene_of_Accident    0.000000\n",
       "LSOA_of_Accident_Location                      1.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.isna().sum()/len(dfa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa['Hour'] = pd.to_datetime(dfa['Time']).dt.hour\n",
    "dfa.Hour.fillna(dfa.Hour.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Location_Easting_OSGR                               0.0\n",
       "Location_Northing_OSGR                              0.0\n",
       "Longitude                                           0.0\n",
       "Latitude                                            0.0\n",
       "Police_Force                                        0.0\n",
       "Accident_Severity                                   0.0\n",
       "Number_of_Vehicles                                  0.0\n",
       "Number_of_Casualties                                0.0\n",
       "Date                                                0.0\n",
       "Day_of_Week                                         0.0\n",
       "Time                                                0.0\n",
       "Local_Authority_(District)                          0.0\n",
       "Local_Authority_(Highway)                           0.0\n",
       "1st_Road_Class                                      0.0\n",
       "1st_Road_Number                                     0.0\n",
       "Road_Type                                      0.055125\n",
       "Speed_limit                                         0.0\n",
       "Junction_Detail                                 0.00005\n",
       "Junction_Control                               0.318625\n",
       "2nd_Road_Class                                      1.0\n",
       "2nd_Road_Number                                 0.68145\n",
       "Pedestrian_Crossing-Human_Control              0.924775\n",
       "Pedestrian_Crossing-Physical_Facilities        0.924775\n",
       "Light_Conditions                               0.000025\n",
       "Weather_Conditions                                  0.0\n",
       "Road_Surface_Conditions                        0.000025\n",
       "Special_Conditions_at_Site                          1.0\n",
       "Carriageway_Hazards                            0.006325\n",
       "Urban_or_Rural_Area                                 1.0\n",
       "Did_Police_Officer_Attend_Scene_of_Accident         1.0\n",
       "LSOA_of_Accident_Location                           0.0\n",
       "Hour                                                0.0\n",
       "dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#for i,k in enumerate(accidents):\n",
    "np.abs(dfa[dfa == -1].sum())/len(dfa)\n",
    "    \n",
    "#for i,k in enumerate(accidents):\n",
    "   # accidents.drop(index=accidents[accidents[k] == -1].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.drop(['Did_Police_Officer_Attend_Scene_of_Accident','Urban_or_Rural_Area',\n",
    "                'Junction_Control','2nd_Road_Class',\n",
    "                'Latitude','Longitude','Location_Easting_OSGR',\n",
    "                'Location_Northing_OSGR','LSOA_of_Accident_Location','Road_Type',\n",
    "          'Junction_Detail','Junction_Control','2nd_Road_Class',\n",
    "          'Pedestrian_Crossing-Physical_Facilities',\n",
    "          'Pedestrian_Crossing-Human_Control','Urban_or_Rural_Area',\n",
    "         'Special_Conditions_at_Site'\n",
    "         ],\n",
    "               inplace=True,axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.drop(['Date'],inplace=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DROP MISSING VALUES =  -1\n",
    "for i,k in enumerate(dfa):\n",
    "    dfa.drop(index=dfa[dfa[k] == -1].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.drop(['Time'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropna's\n",
    "dfa.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"dfa['Local_Authority_(Highway)'].value_counts(normalize=True)\\n# the 9999 it's not a fiable data, it's reference cannot be find at the legend excel and the percentage it's consiredable.\\n# we decided drop that variable.\\ndfa.drop(['Local_Authority_(Highway)'],inplace=True,axis=1)\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''dfa['Local_Authority_(Highway)'].value_counts(normalize=True)\n",
    "# the 9999 it's not a fiable data, it's reference cannot be find at the legend excel and the percentage it's consiredable.\n",
    "# we decided drop that variable.\n",
    "dfa.drop(['Local_Authority_(Highway)'],inplace=True,axis=1)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Police_Force', 'Accident_Severity', 'Number_of_Vehicles',\n",
       "       'Number_of_Casualties', 'Day_of_Week', 'Local_Authority_(District)',\n",
       "       'Local_Authority_(Highway)', '1st_Road_Class', '1st_Road_Number',\n",
       "       'Speed_limit', '2nd_Road_Number', 'Light_Conditions',\n",
       "       'Weather_Conditions', 'Road_Surface_Conditions', 'Carriageway_Hazards',\n",
       "       'Hour'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.Hour = dfa.Hour.astype('int64')\n",
    "dfa.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Police_Force                  int64\n",
       "Accident_Severity             int64\n",
       "Number_of_Vehicles            int64\n",
       "Number_of_Casualties          int64\n",
       "Day_of_Week                   int64\n",
       "Local_Authority_(District)    int64\n",
       "Local_Authority_(Highway)     int64\n",
       "1st_Road_Class                int64\n",
       "1st_Road_Number               int64\n",
       "Speed_limit                   int64\n",
       "2nd_Road_Number               int64\n",
       "Light_Conditions              int64\n",
       "Weather_Conditions            int64\n",
       "Road_Surface_Conditions       int64\n",
       "Carriageway_Hazards           int64\n",
       "Hour                          int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 12601 entries, 197901A1BGF95 to 197901JRNBW79\n",
      "Data columns (total 14 columns):\n",
      " #   Column                      Non-Null Count  Dtype \n",
      "---  ------                      --------------  ----- \n",
      " 0   Police_Force                12601 non-null  object\n",
      " 1   Accident_Severity           12601 non-null  object\n",
      " 2   Number_of_Vehicles          12601 non-null  int64 \n",
      " 3   Number_of_Casualties        12601 non-null  int64 \n",
      " 4   Day_of_Week                 12601 non-null  object\n",
      " 5   Local_Authority_(District)  12601 non-null  object\n",
      " 6   1st_Road_Class              12601 non-null  object\n",
      " 7   Speed_limit                 12601 non-null  object\n",
      " 8   2nd_Road_Number             12601 non-null  object\n",
      " 9   Light_Conditions            12601 non-null  object\n",
      " 10  Weather_Conditions          12601 non-null  object\n",
      " 11  Road_Surface_Conditions     12601 non-null  object\n",
      " 12  Carriageway_Hazards         12601 non-null  object\n",
      " 13  Hour                        12601 non-null  object\n",
      "dtypes: int64(2), object(12)\n",
      "memory usage: 1.7+ MB\n"
     ]
    }
   ],
   "source": [
    "cat_vars = ['Police_Force', 'Accident_Severity','Day_of_Week','1st_Road_Class',\n",
    "       'Speed_limit','Light_Conditions',\n",
    "       'Weather_Conditions', 'Road_Surface_Conditions', 'Carriageway_Hazards',\n",
    "       'Hour']\n",
    "\n",
    "dfa[cat_vars] = dfa[cat_vars].astype(str)\n",
    "dfa.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Police_Force                  object\n",
       "Accident_Severity             object\n",
       "Number_of_Vehicles             int64\n",
       "Number_of_Casualties           int64\n",
       "Day_of_Week                   object\n",
       "Local_Authority_(District)    object\n",
       "Local_Authority_(Highway)     object\n",
       "1st_Road_Class                object\n",
       "1st_Road_Number               object\n",
       "Speed_limit                   object\n",
       "2nd_Road_Number               object\n",
       "Light_Conditions              object\n",
       "Weather_Conditions            object\n",
       "Road_Surface_Conditions       object\n",
       "Carriageway_Hazards           object\n",
       "Hour                          object\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore') # allows handling new values\n",
    "\n",
    "dfa2 = encoder.fit_transform(dfa[cat_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1., 0., 1., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.],\n",
       "        [1., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfa2.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_vars =['Number_of_Vehicles','Number_of_Casualties']\n",
    "scaler = StandardScaler()\n",
    "num_scaler = dfa[num_vars]=scaler.fit_transform(dfa[num_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "# acc_clean.hist(figsize=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate labelencoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# apply le on categorical feature columns\n",
    "dfa[cat_vars] = dfa[cat_vars].apply(lambda col: le.fit_transform(col))    \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "#One-hot-encode the categorical columns.\n",
    "#Unfortunately outputs an array instead of dataframe.\n",
    "array_hot_encoded = ohe.fit_transform(dfa[cat_vars])\n",
    "\n",
    "#Convert it to df\n",
    "data_hot_encoded = pd.DataFrame(array_hot_encoded, index=dfa.index)\n",
    "\n",
    "#Extract only the columns that didnt need to be encoded\n",
    "data_other_cols = dfa.drop(columns=cat_vars)\n",
    "\n",
    "#Concatenate the two dataframes : \n",
    "data_out = pd.concat([data_hot_encoded, data_other_cols], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfadata_hot_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = acc_clean['Accident_Severity']\n",
    "features = acc_clean.drop(['Accident_Severity'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore') # allows handling new values\n",
    "\n",
    "sparse = encoder.fit_transform(#HERE THE DATAFRAME.dropna().values.reshape(-1,1))\n",
    "sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_clean['Local_Authority_(Highway)'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_clean.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_clean.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_clean.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_clean['Date'] = pd.to_datetime(acc_clean['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_clean.drop(['Time'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_clean.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfa.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = dfa[dfa.columns[1:2]]\n",
    "features = dfa[dfa.columns[2:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "lr.fit(X_train, y_train)\n",
    "predictions = lr.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision Score : \",precision_score(y_test, predictions, \n",
    "                                           pos_label='positive'\n",
    "                                           average='micro'))\n",
    "print(\"Recall Score : \",recall_score(y_test, predictions, \n",
    "                                           pos_label='positive'\n",
    "                                           average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(X_test, ys_test, ys_hat):\n",
    "    #plt.scatter(X_test, ys_test)\n",
    "    #plt.scatter(X_test, ys_hat)\n",
    "\n",
    "    mse = mean_squared_error(ys_test, ys_hat)\n",
    "    mae = mean_absolute_error(ys_test, ys_hat)\n",
    "    mape = np.mean(np.abs(ys_test - ys_hat) / ys_test)\n",
    "    ev = explained_variance_score(ys_test, ys_hat)\n",
    "    f1s = f1_score(y_test,ys_hat)\n",
    "\n",
    "    return mse, mae, mape, ev, f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hexen\\anaconda3\\envs\\tfm\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 81.29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hexen\\anaconda3\\envs\\tfm\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hexen\\anaconda3\\envs\\tfm\\lib\\site-packages\\sklearn\\utils\\validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\hexen\\anaconda3\\envs\\tfm\\lib\\site-packages\\sklearn\\utils\\validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\hexen\\anaconda3\\envs\\tfm\\lib\\site-packages\\sklearn\\utils\\validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\hexen\\anaconda3\\envs\\tfm\\lib\\site-packages\\sklearn\\utils\\validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\hexen\\anaconda3\\envs\\tfm\\lib\\site-packages\\sklearn\\utils\\validation.py:63: FutureWarning: Arrays of bytes/strings is being converted to decimal numbers if dtype='numeric'. This behavior is deprecated in 0.24 and will be removed in 1.1 (renaming of 0.26). Please convert your data to numeric values explicitly instead.\n",
      "  return f(*args, **kwargs)\n"
     ]
    },
    {
     "ename": "UFuncTypeError",
     "evalue": "ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U1'), dtype('<U1')) -> dtype('<U1')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUFuncTypeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-117-23ae9578ccca>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Accuracy: %.2f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0myhat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-116-fe91f452fa6f>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(X_test, ys_test, ys_hat)\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmae\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_absolute_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mmape\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys_test\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mys_hat\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mys_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplained_variance_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mys_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mys_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mf1s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mys_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUFuncTypeError\u001b[0m: ufunc 'subtract' did not contain a loop with signature matching types (dtype('<U1'), dtype('<U1')) -> dtype('<U1')"
     ]
    }
   ],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score,recall_score,f1_score,\\\n",
    "precision_score,roc_auc_score,roc_curve,mean_absolute_percentage_error\n",
    "# define the location of the dataset\n",
    "# load the dataset\n",
    "dataset = read_csv(url, header=None)\n",
    "# retrieve the array of data\n",
    "data = dfa.values\n",
    "# separate into input and output columns\n",
    "X = data[:, 2:].astype(str)\n",
    "y = data[:,1:2].astype(str)\n",
    "# split the dataset into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=1)\n",
    "#one-hot encode input variables\n",
    "'''onehot_encoder = OneHotEncoder()\n",
    "onehot_encoder.fit(X_train)\n",
    "X_train = onehot_encoder.transform(X_train)\n",
    "X_test = onehot_encoder.transform(X_test)'''\n",
    "#ordinal encode target variable\n",
    "'''label_encoder = LabelEncoder()\n",
    "label_encoder.fit(y_train)\n",
    "y_train = label_encoder.transform(y_train)\n",
    "y_test = label_encoder.transform(y_test)'''\n",
    "# define the model\n",
    "model = LogisticRegression()\n",
    "# fit on the training set\n",
    "model.fit(X_train, y_train)\n",
    "# predict on test set\n",
    "yhat = model.predict(X_test)\n",
    "# evaluate predictions\n",
    "accuracy = accuracy_score(y_test, yhat)\n",
    "print('Accuracy: %.2f' % (accuracy*100))\n",
    "\n",
    "evaluate(X_test,y_test,yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "warning: LF will be replaced by CRLF in .ipynb_checkpoints/tfm-checkpoint.ipynb.\n",
      "The file will have its original line endings in your working directory\n",
      "warning: LF will be replaced by CRLF in tfm.ipynb.\n",
      "The file will have its original line endings in your working directory\n"
     ]
    }
   ],
   "source": [
    "!git add ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, ..., 2, 2, 2])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FRONT END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_cols = ['Local_Authority_(Highway)'] \n",
    "\n",
    "# instantiate labelencoder object\n",
    "le = LabelEncoder()\n",
    "\n",
    "# apply le on categorical feature columns\n",
    "acc_clean[categorical_cols] = acc_clean[categorical_cols].apply(lambda col: le.fit_transform(col))    \n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "\n",
    "#One-hot-encode the categorical columns.\n",
    "#Unfortunately outputs an array instead of dataframe.\n",
    "array_hot_encoded = ohe.fit_transform(data[categorical_cols])\n",
    "\n",
    "#Convert it to df\n",
    "data_hot_encoded = pd.DataFrame(array_hot_encoded, index=data.index)\n",
    "\n",
    "#Extract only the columns that didnt need to be encoded\n",
    "data_other_cols = data.drop(columns=categorical_cols)\n",
    "\n",
    "#Concatenate the two dataframes : \n",
    "data_out = pd.concat([data_hot_encoded, data_other_cols], axis=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which columns should be encoded vs scaled\n",
    " \n",
    "columns_to_encode = ['Police_Force', 'Accident_Severity', 'Number_of_Vehicles',\n",
    "       'Number_of_Casualties', 'Day_of_Week', 'Local_Authority_(District)', \n",
    "        '1st_Road_Class', '1st_Road_Number',\n",
    "       'Road_Type', 'Speed_limit', 'Junction_Detail', '2nd_Road_Number',\n",
    "       'Pedestrian_Crossing-Human_Control',\n",
    "       'Pedestrian_Crossing-Physical_Facilities', 'Light_Conditions',\n",
    "       'Weather_Conditions', 'Road_Surface_Conditions',\n",
    "       'Special_Conditions_at_Site', 'Carriageway_Hazards', 'Hour']\n",
    "\n",
    "columns_to_scale  = ['Police_Force', 'Accident_Severity', 'Number_of_Vehicles',\n",
    "       'Number_of_Casualties', 'Day_of_Week', 'Local_Authority_(District)', \n",
    "        '1st_Road_Class', '1st_Road_Number',\n",
    "       'Road_Type', 'Speed_limit', 'Junction_Detail', '2nd_Road_Number',\n",
    "       'Pedestrian_Crossing-Human_Control',\n",
    "       'Pedestrian_Crossing-Physical_Facilities', 'Light_Conditions',\n",
    "       'Weather_Conditions', 'Road_Surface_Conditions',\n",
    "       'Special_Conditions_at_Site', 'Carriageway_Hazards', 'Hour']\n",
    "\n",
    "# Instantiate encoder/scaler\n",
    "scaler = StandardScaler()\n",
    "ohe    = OneHotEncoder(sparse=False)\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "x = acc_clean['Local_Authority_(Highway)']\n",
    "y = label_encoder.fit_transform(x)\n",
    "print(y)\n",
    "\n",
    "encoder = OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "encoder.fit(data)\n",
    "encoder.transform(new_data)\n",
    "\n",
    "\n",
    "#Scale and Encode Separate Columns\n",
    "scaled_columns  = scaler.fit_transform(acc_clean.columns) \n",
    "encoded_columns =    ohe.fit_transform(acc_clean.columns)\n",
    "\n",
    "# Concatenate (Column-Bind) Processed Columns Back Together\n",
    "#processed_data = np.concatenate([scaled_columns, encoded_columns], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Front END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "from dash.dependencies import Input, Output\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "app = dash.Dash(__name__)\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.P(\"Color:\"),\n",
    "    dcc.Dropdown(\n",
    "        id=\"dropdown\",\n",
    "        options=[\n",
    "            {'label': x, 'value': x}\n",
    "            for x in ['Gold', 'MediumTurquoise', 'LightGreen']\n",
    "        ],\n",
    "        value='Gold',\n",
    "        clearable=False,\n",
    "    ),\n",
    "    dcc.Graph(id=\"graph\"),\n",
    "])\n",
    "\n",
    "@app.callback(\n",
    "    Output(\"graph\", \"figure\"), \n",
    "    [Input(\"dropdown\", \"value\")])\n",
    "def display_color(color):\n",
    "    fig = go.Figure(\n",
    "        data=go.Bar(y=[2, 3, 1], marker_color=color))\n",
    "    return fig\n",
    "app.run_server(host= '127.0.0.1',debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app.layout = html.Div(\n",
    "\n",
    "    children=[\n",
    "\n",
    "        html.H1(children=\"Avocado Analytics\",),\n",
    "\n",
    "        html.P(\n",
    "\n",
    "            children=\"Analyze the behavior of avocado prices\"\n",
    "\n",
    "            \" and the number of avocados sold in the US\"\n",
    "\n",
    "            \" between 2015 and 2018\",\n",
    "\n",
    "        ),\n",
    "\n",
    "        dcc.Graph(\n",
    "\n",
    "            figure={\n",
    "\n",
    "                \"data\": [\n",
    "\n",
    "                    {\n",
    "\n",
    "                        \"x\": data[\"Date\"],\n",
    "\n",
    "                        \"y\": data[\"AveragePrice\"],\n",
    "\n",
    "                        \"type\": \"lines\",\n",
    "\n",
    "                    },\n",
    "\n",
    "                ],\n",
    "\n",
    "                \"layout\": {\"title\": \"Average Price of Avocados\"},\n",
    "\n",
    "            },\n",
    "\n",
    "        ),\n",
    "\n",
    "        dcc.Graph(\n",
    "\n",
    "            figure={\n",
    "\n",
    "                \"data\": [\n",
    "\n",
    "                    {\n",
    "\n",
    "                        \"x\": data[\"Date\"],\n",
    "\n",
    "                        \"y\": data[\"Total Volume\"],\n",
    "\n",
    "                        \"type\": \"lines\",\n",
    "\n",
    "                    },\n",
    "\n",
    "                ],\n",
    "\n",
    "                \"layout\": {\"title\": \"Avocados Sold\"},\n",
    "\n",
    "            },\n",
    "\n",
    "        ),\n",
    "\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
